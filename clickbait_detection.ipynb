{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRinBnF7AchnI4nJ74xLvl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changmin-jen/clickbait-detection/blob/main/clickbait_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YHmPJMDZiaw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9baf8a-1f58-40ab-c84d-f745603a6f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Clickbait Pair-Fusion (Title/Thumb + STT/Keyframe, Var-Length)\n",
        "# End-to-end Colab script (Top-k pooling for all branches)\n",
        "# ============================================================\n",
        "\n",
        "# -------- 0) 기본 설정 & 드라이브 마운트 --------\n",
        "import os, random, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/clickbait_data\"\n",
        "EMB_NPZ = f\"{ROOT}/embeddings_sbert_dot_v1.npz\"\n",
        "LABEL_XLSX = f\"{ROOT}/clickbait_enriched_caps_QWEN_thumbcaps_qwen.xlsx\"\n",
        "\n",
        "ID_COL = \"id\"; LABEL_COL = \"label\"; SPLIT_COL = \"split\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터\n",
        "BATCH_TRAIN = 64\n",
        "BATCH_EVAL  = 256\n",
        "LR = 1e-4\n",
        "EPOCHS = 50\n",
        "MU = 1.5 #fuse가중비율\n",
        "BR_W = 0.5   # 브랜치 합에 곱할 가중\n",
        "WD = 1e-3\n",
        "HIDDEN = 64\n",
        "DROPOUT = 0.4\n",
        "LABEL_SMOOTH = 0.01\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "XwEXw1WCod4Z"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 1) 시드 고정 --------\n",
        "import numpy as np, torch, pandas as pd\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "set_seed(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAIHiyfaod2M",
        "outputId": "235b8756-97f2-4340-f963-41832f87a001"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 2) NPZ 로딩 --------\n",
        "npz = np.load(EMB_NPZ, allow_pickle=True)\n",
        "print(\"NPZ keys ->\", list(npz.files))\n",
        "\n",
        "def npz_get(npz_obj, candidates):\n",
        "    keys = list(npz_obj.files)\n",
        "    for c in candidates:\n",
        "        if c in keys: return npz_obj[c]\n",
        "        if f\"{c}.npy\" in keys: return npz_obj[f\"{c}.npy\"]\n",
        "    for c in candidates:\n",
        "        m = [k for k in keys if c in k]\n",
        "        if len(m) == 1: return npz_obj[m[0]]\n",
        "    raise KeyError(f\"NPZ에 {candidates} 중 일치 키 없음. 존재키={keys}\")\n",
        "\n",
        "emb_title = npz_get(npz, [\"emb_title\",\"title\"])\n",
        "emb_thumb = npz_get(npz, [\"emb_thumb\",\"thumb\"])\n",
        "emb_stt   = npz_get(npz, [\"emb_stt\",\"stt\"])\n",
        "emb_kf    = npz_get(npz, [\"emb_kf\",\"kf\"])\n",
        "index_ids = npz_get(npz, [\"index\"])\n",
        "\n",
        "def to_2d(arr):\n",
        "    if isinstance(arr, np.ndarray) and arr.ndim == 2: return arr\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype == object: return arr\n",
        "    if isinstance(arr, np.ndarray) and arr.ndim == 1 and arr.dtype == object:\n",
        "        return np.stack([np.asarray(v).reshape(-1) for v in arr], axis=0)\n",
        "    if isinstance(arr, np.ndarray) and arr.ndim == 1: return arr.reshape(1,-1)\n",
        "    return arr\n",
        "\n",
        "emb_title = to_2d(emb_title)\n",
        "emb_thumb = to_2d(emb_thumb)\n",
        "print(\"shapes:\", emb_title.shape, (len(emb_stt),\"object_seq\"),\n",
        "      emb_thumb.shape, (len(emb_kf),\"object_seq\"), \"index_len:\", len(index_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmFNIExqodzz",
        "outputId": "8e48fe96-604e-4da1-ac73-e3e49f82c9a9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPZ keys -> ['emb_title', 'emb_thumb', 'emb_stt', 'emb_kf', 'index', 'title_col', 'stt_col', 'kf_col', 'thumb_col']\n",
            "shapes: (398, 768) (398, 'object_seq') (398, 768) (398, 'object_seq') index_len: 398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 3) 라벨 로딩 & 인덱스 매핑(위치 기반) --------\n",
        "df = pd.read_excel(LABEL_XLSX)\n",
        "df[ID_COL] = df[ID_COL].astype(str).str.strip()\n",
        "df[LABEL_COL] = df[LABEL_COL].astype(str).str.strip().str.lower()\n",
        "df[SPLIT_COL] = df[SPLIT_COL].astype(str).str.strip().str.lower().replace({\"val\":\"valid\"})\n",
        "\n",
        "N = emb_title.shape[0]\n",
        "assert emb_thumb.shape[0]==N and len(emb_stt)==N and len(emb_kf)==N\n",
        "assert len(df)==N, f\"라벨({len(df)}) != 임베딩({N})\"\n",
        "\n",
        "df = df.reset_index(drop=True).copy()\n",
        "df[\"emb_idx\"] = np.arange(N, dtype=int)\n",
        "df[\"y\"] = (df[LABEL_COL] == \"clickbait\").astype(\"float32\")\n",
        "\n",
        "df_tr = df[df[SPLIT_COL]==\"train\"].reset_index(drop=True)\n",
        "df_va = df[df[SPLIT_COL]==\"valid\"].reset_index(drop=True)\n",
        "df_te = df[df[SPLIT_COL]==\"test\"].reset_index(drop=True)\n",
        "print(\"split sizes:\", len(df_tr), len(df_va), len(df_te))\n",
        "\n",
        "# 클래스 가중치(선택)\n",
        "pos = float(df_tr[\"y\"].sum()); neg = float((1 - df_tr[\"y\"]).sum())\n",
        "pos_weight = torch.tensor([(neg / max(pos, 1.0))], device=device)\n",
        "print(\"pos_weight:\", pos_weight.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1LeNC8fojbk",
        "outputId": "40d53403-6d67-4d07-a270-24e752a9ef64"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split sizes: 200 98 100\n",
            "pos_weight: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 4) Dataset / DataLoader (정규화 포함) --------\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 고정 길이 L2 정규화 적용\n",
        "def l2n(t):\n",
        "    return t / (t.norm(dim=1, keepdim=True) + 1e-8)  # 두 벡터를 단위벡터로 만들어 크기가 같게한다(크기가 같은 벡터의 내적은 코사인유사도 이기때문)\n",
        "\n",
        "T_title = l2n(torch.from_numpy(emb_title).float())\n",
        "T_thumb = l2n(torch.from_numpy(emb_thumb).float())\n",
        "\n",
        "# 시퀀스 정리 함수\n",
        "def get_seq(obj_arr, i):\n",
        "    x = obj_arr[i]\n",
        "    x = torch.as_tensor(x, dtype=torch.float32)\n",
        "    if x.ndim == 1:\n",
        "        x = x.unsqueeze(0)\n",
        "    if x.size(0) == 0:  # 빈 시퀀스 방어\n",
        "        x = torch.zeros(1, x.size(1))\n",
        "    # 시퀀스 내부 L2 정규화\n",
        "    x = x / (x.norm(dim=1, keepdim=True) + 1e-8)\n",
        "    return x\n",
        "\n",
        "class PairFusionVarLenDS(Dataset):\n",
        "    # 데이터셋: 제목, 썸네일, STT, 키프레임\n",
        "    def __init__(self, frame):\n",
        "        self.idx = frame[\"emb_idx\"].to_numpy().astype(int)\n",
        "        self.y = frame[\"y\"].to_numpy().astype(np.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.idx)\n",
        "    def __getitem__(self, i):\n",
        "        j = int(self.idx[i])\n",
        "        return {\n",
        "            \"t\": T_title[j], \"th\": T_thumb[j],\n",
        "            \"s\": get_seq(emb_stt, j), \"k\": get_seq(emb_kf, j),\n",
        "            \"y\": torch.tensor(self.y[i])\n",
        "        }\n",
        "\n",
        "def pad_and_mask(seqs):\n",
        "    lens = [x.size(0) for x in seqs]\n",
        "    L = max(lens)\n",
        "    d = seqs[0].size(1)\n",
        "    B = len(seqs)\n",
        "    out = torch.zeros(B, L, d)\n",
        "    mask = torch.zeros(B, L, dtype=torch.bool)\n",
        "    for i, x in enumerate(seqs):\n",
        "        out[i, :x.size(0)] = x\n",
        "        mask[i, :x.size(0)] = True\n",
        "    return out, mask\n",
        "\n",
        "def collate_fn(batch):\n",
        "    t = torch.stack([b[\"t\"] for b in batch], 0)\n",
        "    th = torch.stack([b[\"th\"] for b in batch], 0)\n",
        "    s_p, s_m = pad_and_mask([b[\"s\"] for b in batch])\n",
        "    k_p, k_m = pad_and_mask([b[\"k\"] for b in batch])\n",
        "    y = torch.stack([b[\"y\"] for b in batch], 0)\n",
        "    return {\"t\": t, \"th\": th, \"s\": s_p, \"s_mask\": s_m, \"k\": k_p, \"k_mask\": k_m, \"y\": y}\n",
        "\n",
        "# 데이터로더 정의\n",
        "train_dl = DataLoader(PairFusionVarLenDS(df_tr), batch_size=BATCH_TRAIN, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n",
        "val_dl = DataLoader(PairFusionVarLenDS(df_va), batch_size=BATCH_EVAL, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n",
        "test_dl = DataLoader(PairFusionVarLenDS(df_te), batch_size=BATCH_EVAL, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n",
        "\n"
      ],
      "metadata": {
        "id": "cEuWvM-Zodr1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 5) 모델  --------\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BRANCH_NAMES = [\"TK\",\"TS\",\"ThK\",\"ThS\"]\n",
        "BRANCH_IDX = {n:i for i,n in enumerate(BRANCH_NAMES)}\n",
        "\n",
        "def pair_features(h1, h2):\n",
        "    return torch.cat([h1, h2, torch.abs(h1-h2), h1*h2], dim=-1)\n",
        "\n",
        "class SeqPool(nn.Module):\n",
        "    def __init__(self, d, mode=\"attn\", k=3, tau=0.5):\n",
        "        super().__init__()\n",
        "        self.mode, self.k, self.tau = mode, k, tau\n",
        "\n",
        "    def forward(self, X, mask, q=None):\n",
        "        if self.mode == \"mean\":\n",
        "            pooled = (X * mask.unsqueeze(-1)).sum(1) / (mask.sum(1, keepdim=True) + 1e-8)\n",
        "            return pooled, None\n",
        "\n",
        "        if self.mode == \"attn\":\n",
        "            assert q is not None\n",
        "            score = F.cosine_similarity(X, q.unsqueeze(1), dim=-1).masked_fill(~mask, -1e9)\n",
        "            alpha = F.softmax(score / self.tau, dim=1)\n",
        "            pooled = (X * alpha.unsqueeze(-1)).sum(1)\n",
        "            return pooled, alpha\n",
        "\n",
        "        if self.mode == \"topk\":\n",
        "            score = X.norm(dim=-1).masked_fill(~mask, -1e9)\n",
        "            k = min(self.k, X.size(1))\n",
        "            idx = torch.topk(score, k, dim=1).indices\n",
        "            b = torch.arange(X.size(0), device=X.device)[:, None]\n",
        "            picked = X[b, idx]\n",
        "            pooled = picked.mean(1)\n",
        "            return pooled, idx\n",
        "\n",
        "        if self.mode == \"topk_sim\":\n",
        "            assert q is not None\n",
        "            score = F.cosine_similarity(X, q.unsqueeze(1), dim=-1).masked_fill(~mask, -1e9)\n",
        "            k = min(self.k, X.size(1))\n",
        "            idx = torch.topk(score, k, dim=1).indices\n",
        "            b = torch.arange(X.size(0), device=X.device)[:, None]\n",
        "            picked = X[b, idx]\n",
        "            pooled = picked.mean(1)\n",
        "            return pooled, score\n",
        "\n",
        "        raise ValueError(self.mode)\n",
        "\n",
        "class BranchMLP(nn.Module):\n",
        "    def __init__(self, d4, hidden=HIDDEN, dropout=DROPOUT, prior_p=None):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d4, hidden), nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, 1)\n",
        "        )\n",
        "        if prior_p is not None:\n",
        "            b = np.log(prior_p/(1-prior_p + 1e-8))\n",
        "            with torch.no_grad():\n",
        "                self.net[-1].bias.fill_(b)\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z).squeeze(-1)\n",
        "\n",
        "class ClickbaitPairFusionVar(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super().__init__()\n",
        "        self.pool_s  = SeqPool(d, mode=\"attn\", tau=0.5)  # STT\n",
        "        self.pool_k  = SeqPool(d, mode=\"attn\", tau=0.5)  # Keyframe\n",
        "\n",
        "        d4 = d * 4\n",
        "        self.pre_norm  = nn.LayerNorm(d)\n",
        "        self.norm_pair = nn.LayerNorm(d4)\n",
        "\n",
        "        self.b_TK  = BranchMLP(d4)\n",
        "        self.b_TS  = BranchMLP(d4)\n",
        "        self.b_ThK = BranchMLP(d4)\n",
        "        self.b_ThS = BranchMLP(d4)\n",
        "\n",
        "        self.norm_z   = nn.LayerNorm(d4)\n",
        "        self.att_w    = nn.Linear(d4, 1, bias=False)\n",
        "        self.fuse_out = nn.Linear(d4, 1)\n",
        "\n",
        "        self.branch_names = BRANCH_NAMES\n",
        "        self.branch_idx   = BRANCH_IDX\n",
        "\n",
        "    def forward(self, t, th, s_pad, s_mask, k_pad, k_mask, use_branches=(\"TK\",\"TS\",\"ThK\",\"ThS\")):\n",
        "        # ---- 1) 브랜치별 쿼리로 풀링 결과 4개 생성 ----\n",
        "        s_by_t,  _  = self.pool_s(s_pad, s_mask, q=t)\n",
        "        s_by_th, _  = self.pool_s(s_pad, s_mask, q=th)\n",
        "        k_by_t,  _  = self.pool_k(k_pad, k_mask, q=t)\n",
        "        k_by_th, _  = self.pool_k(k_pad, k_mask, q=th)\n",
        "\n",
        "        # ---- 2) 정규화 ----\n",
        "        t      = self.pre_norm(t)\n",
        "        th     = self.pre_norm(th)\n",
        "        s_by_t = self.pre_norm(s_by_t)\n",
        "        s_by_th= self.pre_norm(s_by_th)\n",
        "        k_by_t = self.pre_norm(k_by_t)\n",
        "        k_by_th= self.pre_norm(k_by_th)\n",
        "\n",
        "        # ---- 3) 브랜치별 pair 특징 ----\n",
        "        z_TK  = self.norm_pair(pair_features(t,  k_by_t))\n",
        "        z_TS  = self.norm_pair(pair_features(t,  s_by_t))\n",
        "        z_ThK = self.norm_pair(pair_features(th, k_by_th))\n",
        "        z_ThS = self.norm_pair(pair_features(th, s_by_th))\n",
        "\n",
        "        # ---- 4) 브랜치 로짓 ----\n",
        "        s_TK  = self.b_TK(z_TK)\n",
        "        s_TS  = self.b_TS(z_TS)\n",
        "        s_ThK = self.b_ThK(z_ThK)\n",
        "        s_ThS = self.b_ThS(z_ThS)\n",
        "\n",
        "        branch_logits = torch.stack([s_TK, s_TS, s_ThK, s_ThS], 1)  # (B,4)\n",
        "\n",
        "        # ---- 5) 선택된 브랜치만 attention-fuse ----\n",
        "        Z = torch.stack([z_TK, z_TS, z_ThK, z_ThS], dim=1)         # (B,4,4d)\n",
        "        Z = self.norm_z(Z)\n",
        "\n",
        "        idxs = [self.branch_idx[b] for b in use_branches]          # 선택 브랜치 인덱스\n",
        "        Z_sel = Z[:, idxs, :]                                      # (B,m,4d)\n",
        "\n",
        "        alpha_sel = F.softmax(self.att_w(Z_sel).squeeze(-1), dim=1)  # (B,m)\n",
        "        Zf = (Z_sel * alpha_sel.unsqueeze(-1)).sum(1)                # (B,4d)\n",
        "        fuse_logit = self.fuse_out(Zf).squeeze(-1)                   # (B,)\n",
        "\n",
        "        return {\n",
        "            \"branch_logits\": branch_logits,   # (B,4)\n",
        "            \"fuse_logit\": fuse_logit,         # (B,)\n",
        "            \"alpha_sel\": alpha_sel,           # (B,m)\n",
        "            \"idxs\": idxs,                     # 선택된 브랜치 인덱스(해석용)\n",
        "            \"Z\": Z,                           # (B,4,4d) 전체(원하면)\n",
        "            # 디버깅/해석용\n",
        "            \"s_by_t\": s_by_t, \"s_by_th\": s_by_th,\n",
        "            \"k_by_t\": k_by_t, \"k_by_th\": k_by_th,\n",
        "        }\n",
        "\n",
        "d = T_title.shape[1]\n",
        "model = ClickbaitPairFusionVar(d).to(device)\n",
        "print(\"params(M):\", sum(p.numel() for p in model.parameters())/1e6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj5qctwJodkZ",
        "outputId": "84213e42-918d-41de-b8dd-7e5e41dfeb37"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params(M): 0.806917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 6) 학습/평가 --------\n",
        "bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "BRANCH_NAMES = [\"TK\",\"TS\",\"ThK\",\"ThS\"]\n",
        "BRANCH_IDX = {n:i for i,n in enumerate(BRANCH_NAMES)}\n",
        "\n",
        "def run_epoch(dl, train=True, return_preds=False, use_branches=(\"TK\",\"TS\",\"ThK\",\"ThS\")):\n",
        "    model.train(train)\n",
        "    tot, n = 0.0, 0\n",
        "    all_p, all_y = [], []\n",
        "    ctx = torch.enable_grad() if train else torch.no_grad()\n",
        "\n",
        "    idxs = [BRANCH_IDX[b] for b in use_branches]\n",
        "\n",
        "    with ctx:\n",
        "        for B in dl:\n",
        "            y = B[\"y\"].to(device)\n",
        "            y_sm = y * (1 - LABEL_SMOOTH) + 0.5 * LABEL_SMOOTH\n",
        "\n",
        "            out = model(\n",
        "                B[\"t\"].to(device),\n",
        "                B[\"th\"].to(device),\n",
        "                B[\"s\"].to(device),\n",
        "                B[\"s_mask\"].to(device),\n",
        "                B[\"k\"].to(device),\n",
        "                B[\"k_mask\"].to(device),\n",
        "                use_branches=use_branches\n",
        "            )\n",
        "\n",
        "            branch_logits = out[\"branch_logits\"]  # (B,4)\n",
        "            fuse_logit    = out[\"fuse_logit\"]     # (B,)  ※ use_branches로 fuse된 logit\n",
        "\n",
        "            # ---- Loss: 선택 브랜치만 branch loss에 포함 ----\n",
        "            branch_loss = sum(bce(branch_logits[:, i], y_sm) for i in idxs)/ len(idxs)\n",
        "            loss = BR_W * branch_loss + MU * bce(fuse_logit, y_sm)\n",
        "\n",
        "            if train:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            bs = y.size(0)\n",
        "            tot += float(loss) * bs\n",
        "            n += bs\n",
        "\n",
        "            p = torch.sigmoid(fuse_logit).detach().cpu().numpy()\n",
        "            all_p.append(p)\n",
        "            all_y.append(y.detach().cpu().numpy())\n",
        "\n",
        "    all_p = np.concatenate(all_p)\n",
        "    all_y = np.concatenate(all_y)\n",
        "    auc = roc_auc_score(all_y, all_p) if len(np.unique(all_y)) > 1 else float(\"nan\")\n",
        "    acc = accuracy_score(all_y, (all_p >= 0.5).astype(int))\n",
        "\n",
        "    if return_preds:\n",
        "        return tot/n, auc, acc, all_p, all_y\n",
        "    return tot/n, auc, acc\n",
        "\n",
        "\n",
        "# -------- 7) 모델 학습 (세팅별로 따로 학습) --------\n",
        "ABLATIONS = {\n",
        "    \"TS\": (\"TS\",),\n",
        "    \"ThK\": (\"ThK\",),\n",
        "    \"All Branches\": (\"TK\",\"TS\",\"ThK\",\"ThS\"),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, branches in ABLATIONS.items():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TRAINING:\", name, \"use_branches=\", branches)\n",
        "\n",
        "    model = ClickbaitPairFusionVar(d).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n",
        "\n",
        "    best_auc, best_state, no_improve = -1.0, None, 0\n",
        "    patience = 8\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        tr_loss, tr_auc, tr_acc = run_epoch(train_dl, True,  use_branches=branches)\n",
        "        va_loss, va_auc, va_acc = run_epoch(val_dl,   False, use_branches=branches)\n",
        "\n",
        "        print(f\"[{ep:02d}] train loss {tr_loss:.4f} auc {tr_auc:.3f} acc {tr_acc:.3f} | \"\n",
        "              f\"val loss {va_loss:.4f} auc {va_auc:.3f} acc {va_acc:.3f}\")\n",
        "\n",
        "        scheduler.step(va_auc)\n",
        "\n",
        "        if va_auc > best_auc:\n",
        "            best_auc = va_auc\n",
        "            best_state = {k:v.detach().cpu() for k,v in model.state_dict().items()}\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                print(f\"Early stop at epoch {ep} (best VAL AUC={best_auc:.3f})\")\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k:v.to(device) for k,v in best_state.items()})\n",
        "\n",
        "    te_loss, te_auc, te_acc = run_epoch(test_dl, False, use_branches=branches)\n",
        "    print(f\"[{name}] TEST loss {te_loss:.4f} | AUC {te_auc:.3f} | ACC {te_acc:.3f}\")\n",
        "\n",
        "    # 저장(세팅별로 파일명 다르게)\n",
        "    SAVE_PATH = f\"{ROOT}/pair_fusion_{name.replace(' ','_')}.pt\"\n",
        "    torch.save(model.state_dict(), SAVE_PATH)\n",
        "    print(\"saved to:\", SAVE_PATH)\n",
        "\n",
        "    results[name] = {\"val_auc\": best_auc, \"test_auc\": te_auc, \"test_acc\": te_acc}\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "for k,v in results.items():\n",
        "    print(k, v)"
      ],
      "metadata": {
        "id": "eYB6H_mVr1bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yFtAjR3oocRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BRANCH_NAMES = [\"TK\", \"TS\", \"ThK\", \"ThS\"]\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_branch_attention(model, dl, device=\"cuda\",\n",
        "                             use_branches=(\"TK\",\"TS\",\"ThK\",\"ThS\"),\n",
        "                             n_branches=4):\n",
        "    model.eval()\n",
        "    alphas_full = []\n",
        "\n",
        "    for B in dl:\n",
        "        out = model(\n",
        "            B[\"t\"].to(device),\n",
        "            B[\"th\"].to(device),\n",
        "            B[\"s\"].to(device),\n",
        "            B[\"s_mask\"].to(device),\n",
        "            B[\"k\"].to(device),\n",
        "            B[\"k_mask\"].to(device),\n",
        "            use_branches=use_branches\n",
        "        )\n",
        "\n",
        "        a_sel = out[\"alpha_sel\"]   # (B,m)\n",
        "        idxs  = out[\"idxs\"]        # list length m (e.g., [0,1,2,3] subset)\n",
        "\n",
        "        # (B,4)로 복원: 선택된 브랜치 위치에만 alpha_sel을 넣고 나머진 0\n",
        "        Bsz = a_sel.size(0)\n",
        "        a_full = torch.zeros(Bsz, n_branches, device=a_sel.device)\n",
        "        a_full[:, idxs] = a_sel\n",
        "\n",
        "        alphas_full.append(a_full.detach().cpu())\n",
        "\n",
        "    A = torch.cat(alphas_full, dim=0)   # (N,4)\n",
        "    mean_a = A.mean(dim=0).numpy()\n",
        "    std_a  = A.std(dim=0).numpy()\n",
        "    return mean_a, std_a\n",
        "\n",
        "\n",
        "def plot_branch_contribution(val_mean, test_mean,\n",
        "                             branch_names=BRANCH_NAMES,\n",
        "                             title=\"Branch wise Attention Contribution\",\n",
        "                             ylabel=\"Average attention weight\"):\n",
        "    x = np.arange(len(branch_names))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(7,4.2))\n",
        "    plt.bar(x - width/2, val_mean,  width, label=\"VAL\")\n",
        "    plt.bar(x + width/2, test_mean, width, label=\"TEST\")\n",
        "\n",
        "    plt.xticks(x, branch_names)\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ====== 실행 ======\n",
        "# All branches 모델이면 기본 그대로 OK\n",
        "val_mean, val_std = collect_branch_attention(model, val_dl, device=device,\n",
        "                                             use_branches=(\"TK\",\"TS\",\"ThK\",\"ThS\"))\n",
        "test_mean, test_std = collect_branch_attention(model, test_dl, device=device,\n",
        "                                               use_branches=(\"TK\",\"TS\",\"ThK\",\"ThS\"))\n",
        "\n",
        "print(\"VAL mean alpha :\", dict(zip(BRANCH_NAMES, np.round(val_mean, 4))))\n",
        "print(\"TEST mean alpha:\", dict(zip(BRANCH_NAMES, np.round(test_mean, 4))))\n",
        "\n",
        "plot_branch_contribution(val_mean, test_mean)\n",
        "\n"
      ],
      "metadata": {
        "id": "Unm0djqNBY0d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}